{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b562652",
   "metadata": {},
   "source": [
    "# 1.  Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4 #BeautifullSoup ver 4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18364dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c380a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_tags=[]\n",
    "for header in soup.find_all(['h1','h2','h3','h4','h5','h6','h7']):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "\n",
    "header_tags\n",
    "    \n",
    "    #print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9996f3",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc03e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page=requests.get('https://www.imdb.com/chart/top')\n",
    "#page=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "page=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&ref_=adv_prv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the tag in which there are the Movie Names.\n",
    "#Now we will extract the text from these tags one by one by looping over these tags\n",
    "\n",
    "name=[] # empty list for store the\n",
    "\n",
    "'''for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text)\n",
    "name'''\n",
    "\n",
    "for i in soup.find_all('h3',class_='lister-item-header'):\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "    #name.append(i.text)\n",
    "#name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div',class_='inline-block ratings-imdb-rating'):\n",
    "    rate.append(float(i.text))\n",
    "#rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='lister-item-year text-muted unbold'):\n",
    "    year.append(i.text)\n",
    "#year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471381cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(name),len(rate),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Titles':name, 'Rating':rate,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feea7b6",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/india/top-rated-indian-movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1695e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the tag in which there are the Movie Names.\n",
    "#Now we will extract the text from these tags one by one by looping over these tags\n",
    "\n",
    "name=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rate.append(i.text.replace('\\n',''))\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(name),len(rate),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Titles':name, 'Rating':rate,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d6159",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08636133",
   "metadata": {},
   "outputs": [],
   "source": [
    "prpage = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "prpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(prpage.content)\n",
    "prlist =soup.find_all('div',class_=\"presidentListing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name =[]\n",
    "office =[]\n",
    "for content in prlist:\n",
    "    president = content.h3.text\n",
    "    Name.append(president)\n",
    "    term=content.p.text.replace('Term of Office:','')\n",
    "office.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a287973",
   "metadata": {},
   "outputs": [],
   "source": [
    "president = pd.DataFrame(list(zip(Name,office)),columns=['Presidents_name','Term_of_Office'])\n",
    "president"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dd6e0",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d67db",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ed9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76373131",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--pos'):\n",
    "    pos.append(int(i.text))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right'):\n",
    "    pos.append(int(i.text))\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "for i in soup.find_all('span',class_ ='u-hide-phablet'):\n",
    "    if i.text=='':\n",
    "        break\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "team\n",
    "#len(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heading--<span class=\"u-hide-mobile\">Matches</span>\n",
    "\n",
    "matches=[] # empty list for store the amtches\n",
    "points=[]   # empty list for store the points\n",
    "\n",
    "p=0\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    matches.append(int(i.text))\n",
    "#next\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    points.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    if p > 20:\n",
    "        print(matches[p])\n",
    "        exit\n",
    "    else:\n",
    "        if (p%2)==0:\n",
    "            matches.append(int(i.text))\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "\n",
    "print(matches)\n",
    "print(points)\n",
    "\n",
    "#i.find_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06210f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(pos),len(team),len(matches),len(points),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdec098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'TEAM':team,'MATCHES':matches, 'POINT':points,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b38e9",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "batsman=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name'):\n",
    "    batsman.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        batsman.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "batsman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "\n",
    "team.append('PAK')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "    \n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81230077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos),len(batsman),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa561a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BATSMAN':batsman,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c18d92",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136757c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    #print(i.text)\n",
    "    bowler.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        bowler.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "bowler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "\n",
    "team.append('NZ')\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "    \n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6236230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18263f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos),len(bowler),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ca789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BOWLER':bowler,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864218a",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7742c",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96faa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--pos'):\n",
    "    pos.append(int(i.text))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right'):\n",
    "    pos.append(int(i.text))\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "for i in soup.find_all('span',class_ ='u-hide-phablet'):\n",
    "    if i.text=='':\n",
    "        break\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "team\n",
    "#len(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=[] \n",
    "points=[]  \n",
    "\n",
    "p=0\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    matches.append(int(i.text))\n",
    "\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    points.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    if p > 20:\n",
    "        print(matches[p])\n",
    "        exit\n",
    "    else:\n",
    "        if (p%2)==0:\n",
    "            matches.append(int(i.text))\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "    p=p+1\n",
    "\n",
    "print(matches)\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d35519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(pos),len(team),len(matches),len(points),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e286e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'TEAM':team,'MATCHES':matches, 'POINT':points,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c2c00",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08994377",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "print(pos)\n",
    "\n",
    "\n",
    "batsman=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    batsman.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        batsman.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "print(batsman)\n",
    "\n",
    "\n",
    "team=[] # empty list for store the\n",
    "team.append('AUS')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "print(team)\n",
    "\n",
    "\n",
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "print(rating)\n",
    "\n",
    "\n",
    "print(len(pos),len(batsman),len(team),len(rating))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BATSMAN':batsman,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc5b31",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c39a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "print(pos)\n",
    "#____________________________________________\n",
    "\n",
    "allrounder=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    #print(i.text)\n",
    "    allrounder.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        allrounder.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "print(allrounder)\n",
    "\n",
    "#---------------------------------------------\n",
    "team=[] # empty list for store the\n",
    "team.append('AUS')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "print(team)\n",
    "#--------------------------------------------\n",
    "\n",
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "print(rating)\n",
    "#___________________________________________________________________\n",
    "\n",
    "print(len(pos),len(allrounder),len(team),len(rating))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'ALLROUNDER':allrounder,'TEAM':team,'RATING':rating})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651dab3",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=('https://www.cnbc.com/world/?region=world')\n",
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2019a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = soup.find('body').find_all('div',class_=\"LatestNews-headlineWrapper\")\n",
    "for x in headlines:\n",
    "    print(x.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5c4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2661d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4aeab0c",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e88b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://coreyms.com/')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ca2c857",
   "metadata": {},
   "source": [
    "HEADING, DATE, CONTENT, CODE FOR THE VIDEO\n",
    "#heading---h2, 'entry-title',\n",
    "#Date--time,'entry-time'\n",
    "#Content---div,'entry-content'\n",
    "#link---a,'ytp-title-link yt-uix-sessionlink'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01831690",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('a',class_='entry-title-link'):\n",
    "    heading.append(i.text)\n",
    "print(heading)\n",
    "len(heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ee3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('time',class_='entry-time'):\n",
    "    date.append(i.text)\n",
    "print(date)\n",
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4517919",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div',class_='entry-content'):\n",
    "    content.append(i.text)\n",
    "print(content)\n",
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='embed-youtube'):\n",
    "    link.append(i.text)\n",
    "print(link)\n",
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec18307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lengh\n",
    "print(len(heading),len(date),len(content),len(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e585d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'HEADING':heading,'DATE':date, 'CONTENT':content})#'LINK':link \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacf419",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043173cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all=[]\n",
    "paper_title=[]\n",
    "Authors = []\n",
    "Published_date=[]\n",
    "paper_url=[]\n",
    "\n",
    "for i in soup.find_all(\"ul\",class_=\"sc-9zxyh7-0 ffmPq\"):\n",
    "    find_all.append(i.text)\n",
    "find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e89e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"): \n",
    "    paper_title.append(i.text)\n",
    "paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a758e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"): \n",
    "    Authors.append(i.text)\n",
    "Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49802464",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"): \n",
    "    Published_date.append(i.text)\n",
    "Published_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "article=pd.DataFrame({})\n",
    "article['paper_title']=paper_title\n",
    "article['Authors']=Authors\n",
    "article['Published_date']=Published_date\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67304dc2",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.dineout.co.in/goa-restaurants/seafood-cuisine?city_name=goa&limit=21&start=0&cityId=8&listing=1&showAvailableTicket=0&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bac458",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurantname=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    Restaurantname.append(i.text)\n",
    "print(Restaurantname)\n",
    "len(Restaurantname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cuisine=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    b=i.text\n",
    "    b=b.split(\"|\")\n",
    "    Cuisine.append(b[1])\n",
    "print(Cuisine)\n",
    "len(Cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    Location.append(i.text)\n",
    "print(Location)\n",
    "len(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[] # empty list for store the\n",
    "\n",
    "'''for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-5\"):\n",
    "    Ratings.append(i.text)\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-3\"):\n",
    "    Ratings.append(i.text)'''\n",
    "for i in soup.find_all('div', class_=\"img-wrap\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "print(Ratings)\n",
    "len(Ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a991f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageURL=[] # empty list for store the\n",
    "\n",
    "'''for i in soup.find_all('div', class_=\"img cursor\"):\n",
    "    ImageURL.append(i.text)\n",
    "print(ImageURL)\n",
    "'''\n",
    "ImageURL = []\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    ImageURL.append(i['data-src'])\n",
    "\n",
    "\n",
    "\n",
    "len(ImageURL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(Restaurantname),len(Cuisine),len(Location),len(Ratings),len(ImageURL))\n",
    "\n",
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Restaurantname':Restaurantname,'Cuisine':Cuisine,'Location':Location,'Ratings':Ratings,'ImageURL':ImageURL}) #,'LINK':link\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d736c",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank\n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_p'):\n",
    "    Rank.append(i.text)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "Publication=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_t'):\n",
    "    Publication.append(i.text)\n",
    "Publication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_index=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_n'):\n",
    "    if i.text.count>200:\n",
    "        exit\n",
    "    else:\n",
    "        h5_index.append(i.text)\n",
    "h5_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd39819",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_median=[]\n",
    "for i in soup.find_all('td',class_='gsc_mvt_p'):\n",
    "    h5_median.append(i.text)\n",
    "h5_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa057d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Rank),len(Publication),len(h5_index),len(h5_median))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rank':Rank,'Publication':Publication,'h5_index':h5_index,'h5_median':h5_median) #,'LINK':link\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06211c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ae762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a346c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
